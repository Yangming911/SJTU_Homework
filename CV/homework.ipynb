{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9144, 200, 200, 3)\n",
      "(9144,)\n",
      "6400 train samples\n",
      "2744 test samples\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras import backend as K\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "IMAGE_SIZE = 200\n",
    "\n",
    "\n",
    "# 按照指定图像大小调整尺寸\n",
    "def resize_image(image, height=IMAGE_SIZE, width=IMAGE_SIZE):\n",
    "    return cv2.resize(image, (height, width))\n",
    "\n",
    "\n",
    "def read_path(path_name):\n",
    "    for dir_item in os.listdir(path_name):\n",
    "        full_path = os.path.abspath(os.path.join(path_name, dir_item))\n",
    "\n",
    "        if os.path.isdir(full_path):  # 如果是文件夹，继续递归调用\n",
    "            read_path(full_path)\n",
    "        else:  # 文件\n",
    "            if dir_item.endswith('.jpg') or dir_item.endswith('.JPG') or dir_item.endswith('.png'):\n",
    "                image = cv2.imread(full_path)\n",
    "                image = resize_image(image)\n",
    "                images.append(image)\n",
    "                labels.append(path_name)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_dataset(path_name):\n",
    "    images, labels = read_path(path_name)\n",
    "\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "    category = []\n",
    "    for i in labels:\n",
    "        category.append(i.split('/')[-1])\n",
    "    temp = list(set(category))\n",
    "    dic = {}\n",
    "    for i in range(len(temp)):\n",
    "        dic[temp[i]] = i\n",
    "    for i in range(len(category)):\n",
    "        labels[i] = dic[category[i]]\n",
    "    labels = np.array(labels)\n",
    "    print(labels.shape)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, path_name):\n",
    "        # 训练集\n",
    "        self.train_images = None\n",
    "        self.train_lb = None\n",
    "\n",
    "        # 测试集\n",
    "        self.test_images = None\n",
    "        self.test_lb = None\n",
    "\n",
    "        # 数据集加载路径\n",
    "        self.path_name = path_name\n",
    "\n",
    "        # 当前库采用的维度顺序\n",
    "        self.input_shape = None\n",
    "\n",
    "    # 加载数据集并按照交叉验证的原则划分数据集并进行相关预处理工作\n",
    "    def load(self, img_rows=IMAGE_SIZE, img_cols=IMAGE_SIZE,\n",
    "             img_channels=3, nb_classes=102):\n",
    "        # 加载数据集到内存\n",
    "        images, labels = load_dataset(self.path_name)\n",
    "\n",
    "        train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.3,\n",
    "                                                                                random_state=random.randint(0, 100))\n",
    "\n",
    "        # 当前的维度顺序如果为'th'，则输入图片数据时的顺序为：channels,rows,cols，否则:rows,cols,channels\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            self.input_shape = (img_channels, img_rows, img_cols)\n",
    "        else:\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            self.input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "            # 输出训练集、验证集、测试集的数量\n",
    "            print(train_images.shape[0], 'train samples')\n",
    "            print(test_images.shape[0], 'test samples')\n",
    "\n",
    "            self.train_lb = train_labels\n",
    "            self.test_lb = test_labels\n",
    "\n",
    "            # 像素数据浮点化以便归一化\n",
    "            train_images = train_images.astype('float32')\n",
    "            test_images = test_images.astype('float32')\n",
    "\n",
    "            # 将其归一化,图像的各像素值归一化到0~1区间\n",
    "            train_images /= 255\n",
    "            test_images /= 255\n",
    "\n",
    "            self.train_images = train_images\n",
    "            self.test_images = test_images\n",
    "\n",
    "\n",
    "# data = Dataset('/kaggle/input/caltech-101/caltech-101')\n",
    "data = Dataset('D:\\\\Grade3_1\\\\Computer_Vision\\\\AI3604_HW2\\\\caltech-101')\n",
    "data.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO 利用SIFT从训练图像中提取特征\n",
    "# 如果有需要，你也可以在pass之外的地方填写相关代码，请自便，下同。\n",
    "# vec_dict 第i项： i为类别，对应的字典为所有属于该类的sift特征点的信息。注意：kp与des一一对应。\n",
    "vec_dict = {i:{'kp':[], 'des':[]} for i in range(102)}\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "for i in range(data.train_images.shape[0]):\n",
    "    tep = cv2.normalize(data.train_images[i], None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    kp_vector, des_vector = sift.detectAndCompute(tep, None)\n",
    "    \n",
    "\n",
    "    vec_dict[data.train_lb[i]]['kp'].extend(kp_vector)\n",
    "    vec_dict[data.train_lb[i]]['des'].extend(des_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload at class:  0\n",
      "upload at class:  7\n",
      "upload at class:  35\n",
      "upload at class:  38\n",
      "upload at class:  53\n",
      "upload at class:  65\n",
      "upload at class:  89\n",
      "bneck_value: 3252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 统计最少特征点的类别\n",
    "bneck_value = float(\"inf\")\n",
    "for i in range(102):\n",
    "    if len(vec_dict[i]['kp']) < bneck_value:\n",
    "        bneck_value = len(vec_dict[i]['kp'])\n",
    "        \n",
    "        print('upload at class: ', i)\n",
    "for i in range(102):\n",
    "    # kp_list = vec_dict[i]['kp'] = sorted((vec_dict[i]['kp']),\n",
    "    #                                      key=lambda x: x.response,\n",
    "    #                                      reverse=True)\n",
    "    temp = [(vec_dict[i]['kp'][j], vec_dict[i]['des'][j]) for j in range(len(vec_dict[i]['kp'])) ]\n",
    "    temp = sorted(temp, key=lambda x: x[0].response, reverse=True)\n",
    "    for j in range(len(temp)):\n",
    "        vec_dict[i]['kp'][j] = temp[j][0]\n",
    "        vec_dict[i]['des'][j] = temp[j][1]\n",
    "        \n",
    "print('bneck_value:', bneck_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331704, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO 为每个类别选择同样多的特征点用于聚类。特征点个数bneck_value\n",
    "\n",
    "vec_list = vec_dict[0]['des'][0:bneck_value]\n",
    "\n",
    "for i in range(1, 102):\n",
    "    vec_list.extend(vec_dict[i]['des'][0:bneck_value])\n",
    "vec_list = np.float64(vec_list)\n",
    "\n",
    "print(vec_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331704,)\n",
      "93850.14672844611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO 对提取出的特征点使用Kmeans聚类，设定合适的聚类中心个数\n",
    "from sklearn.cluster import KMeans\n",
    "#####\n",
    "N_clusters = 150\n",
    "kmeans = KMeans(n_clusters=N_clusters, random_state=10).fit(vec_list)\n",
    "print(kmeans.labels_.shape)\n",
    "print(kmeans.inertia_/261018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python =  \n",
    "# inertia_ : float\n",
    "    # Sum of squared distances of samples to their closest cluster center,\n",
    "    # weighted by the sample weights if provided.\n",
    "```\n",
    "`inertia` 用来评估簇的个数是否合适，距离越小说明簇分的越好。\n",
    "kmeans inertia 表格：\n",
    "\n",
    "| k | inertia | runtime |\n",
    "| :---: | :---: | :---: |\n",
    "| 1 | 142997.03860247726 | 1.1s |\n",
    "| 10 | 106983.13549884284 | 17.4s |\n",
    "| 20 | 98005.53806102792 | 42.9s |\n",
    "| 50 | 88128.89138771851 | 2m 1.3s |\n",
    "| 100 | 81447.3748741387 | 4m 41.3s |\n",
    "| 150 | 77858.47644890724 | 7m 4.3s |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 150)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO 利用直方图统计每张图像中的特征点所属聚类中心的个数，将直方图归一化后便得到图像的特征向量。\n",
    "num_images = data.train_images.shape[0]\n",
    "hist_vector = np.zeros((num_images, N_clusters))\n",
    "for i in range(num_images):\n",
    "    tep = cv2.normalize(data.train_images[i], None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    #####\n",
    "    kp_vector, des_vector = sift.detectAndCompute(tep, None)\n",
    "    des_vector = np.float64(des_vector)\n",
    "    centers = kmeans.predict(des_vector)\n",
    "    for j in range(N_clusters):\n",
    "        hist_vector[i][j] = (centers == j).sum()/len(centers)\n",
    "    #####\n",
    "print(hist_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3713556851311953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用SVM构建分类器\n",
    "# 你可以自行构建分类器，也可以使用SVM\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(probability=True)\n",
    "classifier.fit(hist_vector, data.train_lb)\n",
    "\n",
    "# TODO 构建测试集并计算模型准确率\n",
    "num_test_images = data.test_images.shape[0]\n",
    "hist_test_vector = np.zeros((num_test_images, N_clusters))\n",
    "for i in range(num_test_images):\n",
    "    tep = cv2.normalize(data.test_images[i], None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "\n",
    "    #####\n",
    "    kp_vector, des_vector = sift.detectAndCompute(tep, None)\n",
    "    des_vector = np.float64(des_vector)\n",
    "    centers = kmeans.predict(des_vector)\n",
    "    for j in range(N_clusters):\n",
    "        hist_test_vector[i][j] = (centers == j).sum()/len(centers)\n",
    "    #####\n",
    "\n",
    "\n",
    "acc = classifier.predict(hist_test_vector)-data.test_lb\n",
    "tep = len(acc[acc==0])\n",
    "print('accuracy', tep/len(data.test_lb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab9842120c1767412ad22ea72b6c2d4923dd7c5bac872d3534b1afe2138b14a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
